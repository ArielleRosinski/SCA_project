{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import jax.numpy as jnp\n",
    "from jax import grad, random, vmap\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/Users/ariellerosinski/My Drive/Cambridge/Project/churchland.npy') \n",
    "X = jnp.array(X) \n",
    "print(X.shape)\n",
    "K, N, T = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - jnp.mean(X, axis=0)                #(K, N, T) - (N, T) = (K, N, T)\n",
    "A = jnp.swapaxes(X_centered, 0, 1)                  #(N, K, T)\n",
    "A = A.reshape(N,-1)                                 #(N, K*T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_X_Y(X, Y, sigma_sqrd):\n",
    "    \"\"\"For two spatial patterns X and Y, the kernel k(x_i,y_i) is equal to sum_i sigma_i^2 x_i y_i\"\"\"\n",
    "    return jnp.dot(X.T * sigma_sqrd, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(alpha, sigma_sqrd):\n",
    "    return jnp.concatenate([alpha.reshape(-1), sigma_sqrd.reshape(-1)]) \n",
    "\n",
    "def unstack(params,K=108,T=61, D=3,N=218):\n",
    "    alpha, sigma_sqrd = jnp.split(params, [K*T*D])\n",
    "    alpha = alpha.reshape(K*T, D)\n",
    "    sigma_sqrd.reshape(N,)\n",
    "    return alpha, sigma_sqrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha(alpha_tilde, A, sigma_sqrd):\n",
    "    K_A_A = K_X_Y(A, A, sigma_sqrd)\n",
    "    K_A_A_reshaped = K_A_A.reshape(K,T,K,T)                          #(K,T,K,T)\n",
    "    means = jnp.mean(K_A_A_reshaped, axis=(0, 2), keepdims=True)     #(1, T, 1, T)\n",
    "    K_A_A_tilde = (K_A_A_reshaped - means).reshape(K*T,K*T)          #(K*T,K*T)\n",
    "    P, S, Pt = jnp.linalg.svd(K_A_A_tilde, full_matrices=False)                           #P is (K*T, K*T) and S is (K*T,)\n",
    "\n",
    "    alpha_tilde_QR, _ = jnp.linalg.qr(alpha_tilde) \n",
    "\n",
    "    alpha = jnp.dot(P , jnp.sqrt(S))[:,None] * alpha_tilde_QR\n",
    "    return alpha\n",
    "\n",
    "def single_pair_loss(alpha_H, sigma_sqrd, A, X_centered, id_1, id_2):\n",
    "    K_A_X = K_X_Y(A, X_centered[id_1], sigma_sqrd)\n",
    "    K_X_A = K_X_Y(X_centered[id_2], A, sigma_sqrd)\n",
    "    \n",
    "    Q = alpha_H.T @ K_A_X @ K_X_A @ alpha_H                         #(KT,D).T @ (KT,T) and (T,KT) @ (KT,D) --> (D,T) @ (T,D) --> (D,D)\n",
    "    QQ_product = jnp.einsum('ij,lm->im', Q, Q)\n",
    "    S_pair = jnp.trace(Q)**2 - jnp.trace(QQ_product)\n",
    "    return S_pair \n",
    "\n",
    "def loss(params, A, X_centered, key, D=3):  \n",
    "    K, N, T = X_centered.shape\n",
    "    alpha_tilde, sigma_sqrd = unstack(params)\n",
    "    alpha = get_alpha(alpha_tilde, A, sigma_sqrd)\n",
    "\n",
    "\n",
    "    alpha_reshaped = alpha.reshape(K,T,D)                           #(K, T, D)\n",
    "    mean = jnp.mean(alpha_reshaped, axis=(0), keepdims=True)        #(1, T, D)\n",
    "    alpha_H = (alpha_reshaped - mean).reshape(K*T,D)                #(K*T,D)\n",
    "\n",
    "    num_pairs = 10  \n",
    "    indices = random.randint(key, shape=(num_pairs*2,), minval=0, maxval=N)\n",
    "    index_pairs = indices.reshape((num_pairs, 2))\n",
    "\n",
    "    batched_loss = vmap(single_pair_loss, in_axes=(None, None, None, None, 0, 0))(alpha_H, sigma_sqrd, A, X_centered, index_pairs[:, 0], index_pairs[:, 1]) #(num_pairs)\n",
    "\n",
    "    S = (2 / (K**2) ) * jnp.sum(batched_loss)\n",
    "    return -S\n",
    "\n",
    "def update(params, A, X_centered, optimizer, opt_state, key):\n",
    "    grad_loss = grad(loss)(params, A, X_centered, key)\n",
    "  \n",
    "    updates, opt_state_updated = optimizer.update(grad_loss, opt_state, params)\n",
    "    params_updated = optax.apply_updates(params, updates)\n",
    "    return params_updated, opt_state_updated\n",
    "\n",
    "def optimize_params(A, X_centered, iterations=100, learning_rate=0.001, D=3, seed=42):\n",
    "    K, N, T = X_centered.shape\n",
    "    key = random.PRNGKey(seed)\n",
    "    \n",
    "    sigma_sqrd = random.normal(key, (N,))\n",
    "    alpha_tilde = random.normal(key, (K*T, D))\n",
    "    \n",
    "    params = stack(alpha_tilde, sigma_sqrd)\n",
    "    \n",
    "    keys = random.split(key, num=iterations)\n",
    "\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    ls_loss = []\n",
    "    for i in range(iterations):\n",
    "        params, opt_state = update(params, A, X_centered,  optimizer, opt_state, keys[i])\n",
    "        ls_loss.append(loss(params, A, X_centered, keys[i]))\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Iteration {i}, S: {-loss(params, A, X_centered,keys[i])}\")\n",
    "    \n",
    "    return params, ls_loss\n",
    "\n",
    "\n",
    "optimized_params = optimize_params(A, X_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENDS HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
