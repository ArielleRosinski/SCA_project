{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [1/1000], Loss: 1.8403\n",
      "Iteration [2/1000], Loss: 2.0977\n",
      "Iteration [3/1000], Loss: 2.1154\n",
      "Iteration [4/1000], Loss: 1.8924\n",
      "Iteration [5/1000], Loss: 1.7459\n",
      "Iteration [6/1000], Loss: 2.0722\n",
      "Iteration [7/1000], Loss: 1.9669\n",
      "Iteration [8/1000], Loss: 1.7213\n",
      "Iteration [9/1000], Loss: 2.0732\n",
      "Iteration [10/1000], Loss: 1.6487\n",
      "Iteration [11/1000], Loss: 1.8943\n",
      "Iteration [12/1000], Loss: 2.0803\n",
      "Iteration [13/1000], Loss: 1.9728\n",
      "Iteration [14/1000], Loss: 2.0205\n",
      "Iteration [15/1000], Loss: 1.8835\n",
      "Iteration [16/1000], Loss: 1.9019\n",
      "Iteration [17/1000], Loss: 1.6087\n",
      "Iteration [18/1000], Loss: 2.0787\n",
      "Iteration [19/1000], Loss: 2.0924\n",
      "Iteration [20/1000], Loss: 2.1334\n",
      "Iteration [21/1000], Loss: 1.9181\n",
      "Iteration [22/1000], Loss: 2.0392\n",
      "Iteration [23/1000], Loss: 1.7874\n",
      "Iteration [24/1000], Loss: 1.8541\n",
      "Iteration [25/1000], Loss: 1.8992\n",
      "Iteration [26/1000], Loss: 1.8396\n",
      "Iteration [27/1000], Loss: 1.8106\n",
      "Iteration [28/1000], Loss: 1.2522\n",
      "Iteration [29/1000], Loss: 1.8024\n",
      "Iteration [30/1000], Loss: 2.0805\n",
      "Iteration [31/1000], Loss: 1.8995\n",
      "Iteration [32/1000], Loss: 1.5775\n",
      "Iteration [33/1000], Loss: 1.5072\n",
      "Iteration [34/1000], Loss: 1.8358\n",
      "Iteration [35/1000], Loss: 1.4501\n",
      "Iteration [36/1000], Loss: 1.5270\n",
      "Iteration [37/1000], Loss: 1.1933\n",
      "Iteration [38/1000], Loss: 1.7482\n",
      "Iteration [39/1000], Loss: 1.9737\n",
      "Iteration [40/1000], Loss: 1.4409\n",
      "Iteration [41/1000], Loss: 1.5817\n",
      "Iteration [42/1000], Loss: 1.3280\n",
      "Iteration [43/1000], Loss: 1.1900\n",
      "Iteration [44/1000], Loss: 1.3971\n",
      "Iteration [45/1000], Loss: 1.4211\n",
      "Iteration [46/1000], Loss: 1.3016\n",
      "Iteration [47/1000], Loss: 1.3382\n",
      "Iteration [48/1000], Loss: 1.0817\n",
      "Iteration [49/1000], Loss: 1.1815\n",
      "Iteration [50/1000], Loss: 1.2910\n",
      "Iteration [51/1000], Loss: 1.2336\n",
      "Iteration [52/1000], Loss: 1.3049\n",
      "Iteration [53/1000], Loss: 1.0494\n",
      "Iteration [54/1000], Loss: 1.2458\n",
      "Iteration [55/1000], Loss: 1.0390\n",
      "Iteration [56/1000], Loss: 1.2227\n",
      "Iteration [57/1000], Loss: 1.0587\n",
      "Iteration [58/1000], Loss: 1.2007\n",
      "Iteration [59/1000], Loss: 1.0102\n",
      "Iteration [60/1000], Loss: 1.0510\n",
      "Iteration [61/1000], Loss: 1.1507\n",
      "Iteration [62/1000], Loss: 1.1205\n",
      "Iteration [63/1000], Loss: 1.1631\n",
      "Iteration [64/1000], Loss: 1.0531\n",
      "Iteration [65/1000], Loss: 1.2301\n",
      "Iteration [66/1000], Loss: 1.0297\n",
      "Iteration [67/1000], Loss: 1.2873\n",
      "Iteration [68/1000], Loss: 1.0213\n",
      "Iteration [69/1000], Loss: 1.2513\n",
      "Iteration [70/1000], Loss: 1.0344\n",
      "Iteration [71/1000], Loss: 1.1825\n",
      "Iteration [72/1000], Loss: 1.0348\n",
      "Iteration [73/1000], Loss: 1.0604\n",
      "Iteration [74/1000], Loss: 1.0914\n",
      "Iteration [75/1000], Loss: 1.0221\n",
      "Iteration [76/1000], Loss: 1.1659\n",
      "Iteration [77/1000], Loss: 1.0332\n",
      "Iteration [78/1000], Loss: 1.1525\n",
      "Iteration [79/1000], Loss: 1.0256\n",
      "Iteration [80/1000], Loss: 1.1171\n",
      "Iteration [81/1000], Loss: 1.0027\n",
      "Iteration [82/1000], Loss: 1.0909\n",
      "Iteration [83/1000], Loss: 1.0463\n",
      "Iteration [84/1000], Loss: 1.0563\n",
      "Iteration [85/1000], Loss: 1.0568\n",
      "Iteration [86/1000], Loss: 1.0185\n",
      "Iteration [87/1000], Loss: 1.0703\n",
      "Iteration [88/1000], Loss: 1.0078\n",
      "Iteration [89/1000], Loss: 1.0680\n",
      "Iteration [90/1000], Loss: 1.0039\n",
      "Iteration [91/1000], Loss: 1.0467\n",
      "Iteration [92/1000], Loss: 1.0057\n",
      "Iteration [93/1000], Loss: 1.0308\n",
      "Iteration [94/1000], Loss: 1.0057\n",
      "Iteration [95/1000], Loss: 1.0288\n",
      "Iteration [96/1000], Loss: 1.0098\n",
      "Iteration [97/1000], Loss: 1.0076\n",
      "Iteration [98/1000], Loss: 1.0114\n",
      "Iteration [99/1000], Loss: 1.0040\n",
      "Iteration [100/1000], Loss: 1.0121\n",
      "Iteration [101/1000], Loss: 1.0043\n",
      "Iteration [102/1000], Loss: 1.0128\n",
      "Iteration [103/1000], Loss: 1.0088\n",
      "Iteration [104/1000], Loss: 1.0065\n",
      "Iteration [105/1000], Loss: 1.0083\n",
      "Iteration [106/1000], Loss: 1.0016\n",
      "Iteration [107/1000], Loss: 1.0005\n",
      "Iteration [108/1000], Loss: 1.0020\n",
      "Iteration [109/1000], Loss: 1.0019\n",
      "Iteration [110/1000], Loss: 1.0035\n",
      "Iteration [111/1000], Loss: 1.0017\n",
      "Iteration [112/1000], Loss: 1.0044\n",
      "Iteration [113/1000], Loss: 1.0011\n",
      "Iteration [114/1000], Loss: 1.0029\n",
      "Iteration [115/1000], Loss: 1.0005\n",
      "Iteration [116/1000], Loss: 1.0028\n",
      "Iteration [117/1000], Loss: 1.0006\n",
      "Iteration [118/1000], Loss: 1.0009\n",
      "Iteration [119/1000], Loss: 1.0001\n",
      "Iteration [120/1000], Loss: 1.0018\n",
      "Iteration [121/1000], Loss: 1.0015\n",
      "Iteration [122/1000], Loss: 1.0013\n",
      "Iteration [123/1000], Loss: 1.0007\n",
      "Iteration [124/1000], Loss: 1.0007\n",
      "Iteration [125/1000], Loss: 1.0003\n",
      "Iteration [126/1000], Loss: 1.0013\n",
      "Iteration [127/1000], Loss: 1.0007\n",
      "Iteration [128/1000], Loss: 1.0011\n",
      "Iteration [129/1000], Loss: 1.0012\n",
      "Iteration [130/1000], Loss: 1.0004\n",
      "Iteration [131/1000], Loss: 1.0016\n",
      "Iteration [132/1000], Loss: 1.0010\n",
      "Iteration [133/1000], Loss: 1.0012\n",
      "Iteration [134/1000], Loss: 1.0012\n",
      "Iteration [135/1000], Loss: 1.0009\n",
      "Iteration [136/1000], Loss: 1.0004\n",
      "Iteration [137/1000], Loss: 1.0027\n",
      "Iteration [138/1000], Loss: 1.0045\n",
      "Iteration [139/1000], Loss: 1.0005\n",
      "Iteration [140/1000], Loss: 1.0045\n",
      "Iteration [141/1000], Loss: 1.0007\n",
      "Iteration [142/1000], Loss: 1.0028\n",
      "Iteration [143/1000], Loss: 1.0005\n",
      "Iteration [144/1000], Loss: 1.0022\n",
      "Iteration [145/1000], Loss: 1.0011\n",
      "Iteration [146/1000], Loss: 1.0013\n",
      "Iteration [147/1000], Loss: 1.0005\n",
      "Iteration [148/1000], Loss: 1.0016\n",
      "Iteration [149/1000], Loss: 1.0008\n",
      "Iteration [150/1000], Loss: 1.0019\n",
      "Iteration [151/1000], Loss: 1.0011\n",
      "Iteration [152/1000], Loss: 1.0004\n",
      "Iteration [153/1000], Loss: 1.0008\n",
      "Iteration [154/1000], Loss: 1.0005\n",
      "Iteration [155/1000], Loss: 1.0014\n",
      "Iteration [156/1000], Loss: 1.0011\n",
      "Iteration [157/1000], Loss: 1.0013\n",
      "Iteration [158/1000], Loss: 1.0017\n",
      "Iteration [159/1000], Loss: 1.0013\n",
      "Iteration [160/1000], Loss: 1.0058\n",
      "Iteration [161/1000], Loss: 1.0006\n",
      "Iteration [162/1000], Loss: 1.0052\n",
      "Iteration [163/1000], Loss: 1.0005\n",
      "Iteration [164/1000], Loss: 1.0082\n",
      "Iteration [165/1000], Loss: 1.0030\n",
      "Iteration [166/1000], Loss: 1.0042\n",
      "Iteration [167/1000], Loss: 1.0038\n",
      "Iteration [168/1000], Loss: 1.0015\n",
      "Iteration [169/1000], Loss: 1.0028\n",
      "Iteration [170/1000], Loss: 1.0005\n",
      "Iteration [171/1000], Loss: 1.0019\n",
      "Iteration [172/1000], Loss: 1.0016\n",
      "Iteration [173/1000], Loss: 1.0088\n",
      "Iteration [174/1000], Loss: 1.0008\n",
      "Iteration [175/1000], Loss: 1.0036\n",
      "Iteration [176/1000], Loss: 1.0007\n",
      "Iteration [177/1000], Loss: 1.0016\n",
      "Iteration [178/1000], Loss: 1.0007\n",
      "Iteration [179/1000], Loss: 1.0029\n",
      "Iteration [180/1000], Loss: 1.0005\n",
      "Iteration [181/1000], Loss: 1.0007\n",
      "Iteration [182/1000], Loss: 1.0043\n",
      "Iteration [183/1000], Loss: 1.0057\n",
      "Iteration [184/1000], Loss: 1.0017\n",
      "Iteration [185/1000], Loss: 1.0047\n",
      "Iteration [186/1000], Loss: 1.0072\n",
      "Iteration [187/1000], Loss: 1.0297\n",
      "Iteration [188/1000], Loss: 1.0114\n",
      "Iteration [189/1000], Loss: 1.0065\n",
      "Iteration [190/1000], Loss: 1.0166\n",
      "Iteration [191/1000], Loss: 1.0008\n",
      "Iteration [192/1000], Loss: 1.0118\n",
      "Iteration [193/1000], Loss: 1.0220\n",
      "Iteration [194/1000], Loss: 1.0012\n",
      "Iteration [195/1000], Loss: 1.0087\n",
      "Iteration [196/1000], Loss: 1.0011\n",
      "Iteration [197/1000], Loss: 1.0080\n",
      "Iteration [198/1000], Loss: 1.0063\n",
      "Iteration [199/1000], Loss: 1.0014\n",
      "Iteration [200/1000], Loss: 1.0030\n",
      "Iteration [201/1000], Loss: 1.0002\n",
      "Iteration [202/1000], Loss: 1.0016\n",
      "Iteration [203/1000], Loss: 1.0006\n",
      "Iteration [204/1000], Loss: 1.0007\n",
      "Iteration [205/1000], Loss: 1.0002\n",
      "Iteration [206/1000], Loss: 1.0025\n",
      "Iteration [207/1000], Loss: 1.0007\n",
      "Iteration [208/1000], Loss: 1.0039\n",
      "Iteration [209/1000], Loss: 1.0094\n",
      "Iteration [210/1000], Loss: 1.0002\n",
      "Iteration [211/1000], Loss: 1.0076\n",
      "Iteration [212/1000], Loss: 1.0034\n",
      "Iteration [213/1000], Loss: 1.0020\n",
      "Iteration [214/1000], Loss: 1.0043\n",
      "Iteration [215/1000], Loss: 1.0005\n",
      "Iteration [216/1000], Loss: 1.0064\n",
      "Iteration [217/1000], Loss: 1.0026\n",
      "Iteration [218/1000], Loss: 1.0051\n",
      "Iteration [219/1000], Loss: 1.0251\n",
      "Iteration [220/1000], Loss: 1.0156\n",
      "Iteration [221/1000], Loss: 1.0047\n",
      "Iteration [222/1000], Loss: 1.0206\n",
      "Iteration [223/1000], Loss: 1.0029\n",
      "Iteration [224/1000], Loss: 1.0072\n",
      "Iteration [225/1000], Loss: 1.0057\n",
      "Iteration [226/1000], Loss: 1.0023\n",
      "Iteration [227/1000], Loss: 1.0150\n",
      "Iteration [228/1000], Loss: 1.0103\n",
      "Iteration [229/1000], Loss: 1.0004\n",
      "Iteration [230/1000], Loss: 1.0015\n",
      "Iteration [231/1000], Loss: 1.0005\n",
      "Iteration [232/1000], Loss: 1.0008\n",
      "Iteration [233/1000], Loss: 1.0015\n",
      "Iteration [234/1000], Loss: 1.0003\n",
      "Iteration [235/1000], Loss: 1.0004\n",
      "Iteration [236/1000], Loss: 1.0025\n",
      "Iteration [237/1000], Loss: 1.0075\n",
      "Iteration [238/1000], Loss: 1.0066\n",
      "Iteration [239/1000], Loss: 1.0010\n",
      "Iteration [240/1000], Loss: 1.0013\n",
      "Iteration [241/1000], Loss: 1.0024\n",
      "Iteration [242/1000], Loss: 1.0019\n",
      "Iteration [243/1000], Loss: 1.0020\n",
      "Iteration [244/1000], Loss: 1.0002\n",
      "Iteration [245/1000], Loss: 1.0028\n",
      "Iteration [246/1000], Loss: 1.0017\n",
      "Iteration [247/1000], Loss: 1.0028\n",
      "Iteration [248/1000], Loss: 1.0061\n",
      "Iteration [249/1000], Loss: 1.0011\n",
      "Iteration [250/1000], Loss: 1.0043\n",
      "Iteration [251/1000], Loss: 1.0048\n",
      "Iteration [252/1000], Loss: 1.0027\n",
      "Iteration [253/1000], Loss: 1.0002\n",
      "Iteration [254/1000], Loss: 1.0027\n",
      "Iteration [255/1000], Loss: 1.0022\n",
      "Iteration [256/1000], Loss: 1.0003\n",
      "Iteration [257/1000], Loss: 1.0032\n",
      "Iteration [258/1000], Loss: 1.0032\n",
      "Iteration [259/1000], Loss: 1.0001\n",
      "Iteration [260/1000], Loss: 1.0038\n",
      "Iteration [261/1000], Loss: 1.0021\n",
      "Iteration [262/1000], Loss: 1.0025\n",
      "Iteration [263/1000], Loss: 1.0125\n",
      "Iteration [264/1000], Loss: 1.0038\n",
      "Iteration [265/1000], Loss: 1.0033\n",
      "Iteration [266/1000], Loss: 1.0163\n",
      "Iteration [267/1000], Loss: 1.0074\n",
      "Iteration [268/1000], Loss: 1.0009\n",
      "Iteration [269/1000], Loss: 1.0104\n",
      "Iteration [270/1000], Loss: 1.0073\n",
      "Iteration [271/1000], Loss: 1.0015\n",
      "Iteration [272/1000], Loss: 1.0096\n",
      "Iteration [273/1000], Loss: 1.0002\n",
      "Iteration [274/1000], Loss: 1.0126\n",
      "Iteration [275/1000], Loss: 1.0127\n",
      "Iteration [276/1000], Loss: 1.0006\n",
      "Iteration [277/1000], Loss: 1.0058\n",
      "Iteration [278/1000], Loss: 1.0020\n",
      "Iteration [279/1000], Loss: 1.0014\n",
      "Iteration [280/1000], Loss: 1.0038\n",
      "Iteration [281/1000], Loss: 1.0016\n",
      "Iteration [282/1000], Loss: 1.0007\n",
      "Iteration [283/1000], Loss: 1.0006\n",
      "Iteration [284/1000], Loss: 1.0006\n",
      "Iteration [285/1000], Loss: 1.0011\n",
      "Iteration [286/1000], Loss: 1.0007\n",
      "Iteration [287/1000], Loss: 1.0002\n",
      "Iteration [288/1000], Loss: 1.0009\n",
      "Iteration [289/1000], Loss: 1.0015\n",
      "Iteration [290/1000], Loss: 1.0004\n",
      "Iteration [291/1000], Loss: 1.0006\n",
      "Iteration [292/1000], Loss: 1.0007\n",
      "Iteration [293/1000], Loss: 1.0028\n",
      "Iteration [294/1000], Loss: 1.0025\n",
      "Iteration [295/1000], Loss: 1.0007\n",
      "Iteration [296/1000], Loss: 1.0035\n",
      "Iteration [297/1000], Loss: 1.0115\n",
      "Iteration [298/1000], Loss: 1.0005\n",
      "Iteration [299/1000], Loss: 1.0135\n",
      "Iteration [300/1000], Loss: 1.0248\n",
      "Iteration [301/1000], Loss: 1.0021\n",
      "Iteration [302/1000], Loss: 1.0100\n",
      "Iteration [303/1000], Loss: 1.0238\n",
      "Iteration [304/1000], Loss: 1.0114\n",
      "Iteration [305/1000], Loss: 1.0031\n",
      "Iteration [306/1000], Loss: 1.0250\n",
      "Iteration [307/1000], Loss: 1.0122\n",
      "Iteration [308/1000], Loss: 1.0035\n",
      "Iteration [309/1000], Loss: 1.0284\n",
      "Iteration [310/1000], Loss: 1.0114\n",
      "Iteration [311/1000], Loss: 1.0012\n",
      "Iteration [312/1000], Loss: 1.0178\n",
      "Iteration [313/1000], Loss: 1.0158\n",
      "Iteration [314/1000], Loss: 1.0082\n",
      "Iteration [315/1000], Loss: 1.0415\n",
      "Iteration [316/1000], Loss: 1.0664\n",
      "Iteration [317/1000], Loss: 1.0078\n",
      "Iteration [318/1000], Loss: 1.0173\n",
      "Iteration [319/1000], Loss: 1.0895\n",
      "Iteration [320/1000], Loss: 1.1435\n",
      "Iteration [321/1000], Loss: 1.0449\n",
      "Iteration [322/1000], Loss: 1.0686\n",
      "Iteration [323/1000], Loss: 1.1864\n",
      "Iteration [324/1000], Loss: 1.0932\n",
      "Iteration [325/1000], Loss: 1.0179\n",
      "Iteration [326/1000], Loss: 1.1988\n",
      "Iteration [327/1000], Loss: 1.1243\n",
      "Iteration [328/1000], Loss: 1.0064\n",
      "Iteration [329/1000], Loss: 1.1528\n",
      "Iteration [330/1000], Loss: 1.1395\n",
      "Iteration [331/1000], Loss: 1.0177\n",
      "Iteration [332/1000], Loss: 1.2059\n",
      "Iteration [333/1000], Loss: 1.0797\n",
      "Iteration [334/1000], Loss: 1.0279\n",
      "Iteration [335/1000], Loss: 1.1376\n",
      "Iteration [336/1000], Loss: 1.0129\n",
      "Iteration [337/1000], Loss: 1.1016\n",
      "Iteration [338/1000], Loss: 1.1880\n",
      "Iteration [339/1000], Loss: 1.0088\n",
      "Iteration [340/1000], Loss: 1.0908\n",
      "Iteration [341/1000], Loss: 1.0399\n",
      "Iteration [342/1000], Loss: 1.0641\n",
      "Iteration [343/1000], Loss: 1.2204\n",
      "Iteration [344/1000], Loss: 1.0123\n",
      "Iteration [345/1000], Loss: 1.1309\n",
      "Iteration [346/1000], Loss: 1.1509\n",
      "Iteration [347/1000], Loss: 1.0013\n",
      "Iteration [348/1000], Loss: 1.1057\n",
      "Iteration [349/1000], Loss: 1.0415\n",
      "Iteration [350/1000], Loss: 1.0307\n",
      "Iteration [351/1000], Loss: 1.0932\n",
      "Iteration [352/1000], Loss: 1.0034\n",
      "Iteration [353/1000], Loss: 1.1019\n",
      "Iteration [354/1000], Loss: 1.0228\n",
      "Iteration [355/1000], Loss: 1.0301\n",
      "Iteration [356/1000], Loss: 1.0730\n",
      "Iteration [357/1000], Loss: 1.0064\n",
      "Iteration [358/1000], Loss: 1.0847\n",
      "Iteration [359/1000], Loss: 1.0711\n",
      "Iteration [360/1000], Loss: 1.0038\n",
      "Iteration [361/1000], Loss: 1.0784\n",
      "Iteration [362/1000], Loss: 1.0309\n",
      "Iteration [363/1000], Loss: 1.0491\n",
      "Iteration [364/1000], Loss: 1.1727\n",
      "Iteration [365/1000], Loss: 1.0261\n",
      "Iteration [366/1000], Loss: 1.1118\n",
      "Iteration [367/1000], Loss: 1.0867\n",
      "Iteration [368/1000], Loss: 1.0302\n",
      "Iteration [369/1000], Loss: 1.1969\n",
      "Iteration [370/1000], Loss: 1.0353\n",
      "Iteration [371/1000], Loss: 1.0717\n",
      "Iteration [372/1000], Loss: 1.1535\n",
      "Iteration [373/1000], Loss: 1.0212\n",
      "Iteration [374/1000], Loss: 1.0747\n",
      "Iteration [375/1000], Loss: 1.0025\n",
      "Iteration [376/1000], Loss: 1.0943\n",
      "Iteration [377/1000], Loss: 1.0474\n",
      "Iteration [378/1000], Loss: 1.0175\n",
      "Iteration [379/1000], Loss: 1.0728\n",
      "Iteration [380/1000], Loss: 1.0086\n",
      "Iteration [381/1000], Loss: 1.0508\n",
      "Iteration [382/1000], Loss: 1.0190\n",
      "Iteration [383/1000], Loss: 1.0105\n",
      "Iteration [384/1000], Loss: 1.0343\n",
      "Iteration [385/1000], Loss: 1.0090\n",
      "Iteration [386/1000], Loss: 1.0180\n",
      "Iteration [387/1000], Loss: 1.0102\n",
      "Iteration [388/1000], Loss: 1.0138\n",
      "Iteration [389/1000], Loss: 1.0143\n",
      "Iteration [390/1000], Loss: 1.0027\n",
      "Iteration [391/1000], Loss: 1.0037\n",
      "Iteration [392/1000], Loss: 1.0099\n",
      "Iteration [393/1000], Loss: 1.0086\n",
      "Iteration [394/1000], Loss: 1.0032\n",
      "Iteration [395/1000], Loss: 1.0058\n",
      "Iteration [396/1000], Loss: 1.0114\n",
      "Iteration [397/1000], Loss: 1.0066\n",
      "Iteration [398/1000], Loss: 1.0012\n",
      "Iteration [399/1000], Loss: 1.0130\n",
      "Iteration [400/1000], Loss: 1.0155\n",
      "Iteration [401/1000], Loss: 1.0043\n",
      "Iteration [402/1000], Loss: 1.0353\n",
      "Iteration [403/1000], Loss: 1.0325\n",
      "Iteration [404/1000], Loss: 1.0087\n",
      "Iteration [405/1000], Loss: 1.0385\n",
      "Iteration [406/1000], Loss: 1.0098\n",
      "Iteration [407/1000], Loss: 1.0181\n",
      "Iteration [408/1000], Loss: 1.0405\n",
      "Iteration [409/1000], Loss: 1.0022\n",
      "Iteration [410/1000], Loss: 1.0406\n",
      "Iteration [411/1000], Loss: 1.0447\n",
      "Iteration [412/1000], Loss: 1.0239\n",
      "Iteration [413/1000], Loss: 1.0938\n",
      "Iteration [414/1000], Loss: 1.0021\n",
      "Iteration [415/1000], Loss: 1.0622\n",
      "Iteration [416/1000], Loss: 1.0290\n",
      "Iteration [417/1000], Loss: 1.0227\n",
      "Iteration [418/1000], Loss: 1.0330\n",
      "Iteration [419/1000], Loss: 1.0056\n",
      "Iteration [420/1000], Loss: 1.0338\n",
      "Iteration [421/1000], Loss: 1.0033\n",
      "Iteration [422/1000], Loss: 1.0311\n",
      "Iteration [423/1000], Loss: 1.0137\n",
      "Iteration [424/1000], Loss: 1.0137\n",
      "Iteration [425/1000], Loss: 1.0299\n",
      "Iteration [426/1000], Loss: 1.0168\n",
      "Iteration [427/1000], Loss: 1.0010\n",
      "Iteration [428/1000], Loss: 1.0191\n",
      "Iteration [429/1000], Loss: 1.0102\n",
      "Iteration [430/1000], Loss: 1.0077\n",
      "Iteration [431/1000], Loss: 1.0404\n",
      "Iteration [432/1000], Loss: 1.0023\n",
      "Iteration [433/1000], Loss: 1.0250\n",
      "Iteration [434/1000], Loss: 1.0136\n",
      "Iteration [435/1000], Loss: 1.0308\n",
      "Iteration [436/1000], Loss: 1.0790\n",
      "Iteration [437/1000], Loss: 1.0055\n",
      "Iteration [438/1000], Loss: 1.0670\n",
      "Iteration [439/1000], Loss: 1.0388\n",
      "Iteration [440/1000], Loss: 1.0054\n",
      "Iteration [441/1000], Loss: 1.0282\n",
      "Iteration [442/1000], Loss: 1.0020\n",
      "Iteration [443/1000], Loss: 1.0339\n",
      "Iteration [444/1000], Loss: 1.0006\n",
      "Iteration [445/1000], Loss: 1.0246\n",
      "Iteration [446/1000], Loss: 1.0091\n",
      "Iteration [447/1000], Loss: 1.0150\n",
      "Iteration [448/1000], Loss: 1.0279\n",
      "Iteration [449/1000], Loss: 1.0021\n",
      "Iteration [450/1000], Loss: 1.0416\n",
      "Iteration [451/1000], Loss: 1.0276\n",
      "Iteration [452/1000], Loss: 1.0067\n",
      "Iteration [453/1000], Loss: 1.0139\n",
      "Iteration [454/1000], Loss: 1.0156\n",
      "Iteration [455/1000], Loss: 1.0153\n",
      "Iteration [456/1000], Loss: 1.0046\n",
      "Iteration [457/1000], Loss: 1.0062\n",
      "Iteration [458/1000], Loss: 1.0239\n",
      "Iteration [459/1000], Loss: 1.0151\n",
      "Iteration [460/1000], Loss: 1.0061\n",
      "Iteration [461/1000], Loss: 1.0132\n",
      "Iteration [462/1000], Loss: 1.0054\n",
      "Iteration [463/1000], Loss: 1.0332\n",
      "Iteration [464/1000], Loss: 1.0184\n",
      "Iteration [465/1000], Loss: 1.0097\n",
      "Iteration [466/1000], Loss: 1.0385\n",
      "Iteration [467/1000], Loss: 1.0270\n",
      "Iteration [468/1000], Loss: 1.0034\n",
      "Iteration [469/1000], Loss: 1.0290\n",
      "Iteration [470/1000], Loss: 1.0230\n",
      "Iteration [471/1000], Loss: 1.0029\n",
      "Iteration [472/1000], Loss: 1.0092\n",
      "Iteration [473/1000], Loss: 1.0022\n",
      "Iteration [474/1000], Loss: 1.0021\n",
      "Iteration [475/1000], Loss: 1.0049\n",
      "Iteration [476/1000], Loss: 1.0027\n",
      "Iteration [477/1000], Loss: 1.0064\n",
      "Iteration [478/1000], Loss: 1.0007\n",
      "Iteration [479/1000], Loss: 1.0011\n",
      "Iteration [480/1000], Loss: 1.0010\n",
      "Iteration [481/1000], Loss: 1.0030\n",
      "Iteration [482/1000], Loss: 1.0093\n",
      "Iteration [483/1000], Loss: 1.0011\n",
      "Iteration [484/1000], Loss: 1.0041\n",
      "Iteration [485/1000], Loss: 1.0019\n",
      "Iteration [486/1000], Loss: 1.0044\n",
      "Iteration [487/1000], Loss: 1.0147\n",
      "Iteration [488/1000], Loss: 1.0113\n",
      "Iteration [489/1000], Loss: 1.0009\n",
      "Iteration [490/1000], Loss: 1.0158\n",
      "Iteration [491/1000], Loss: 1.0308\n",
      "Iteration [492/1000], Loss: 1.0188\n",
      "Iteration [493/1000], Loss: 1.0029\n",
      "Iteration [494/1000], Loss: 1.0093\n",
      "Iteration [495/1000], Loss: 1.0080\n",
      "Iteration [496/1000], Loss: 1.0112\n",
      "Iteration [497/1000], Loss: 1.0309\n",
      "Iteration [498/1000], Loss: 1.0102\n",
      "Iteration [499/1000], Loss: 1.0043\n",
      "Iteration [500/1000], Loss: 1.0169\n",
      "Iteration [501/1000], Loss: 1.0003\n",
      "Iteration [502/1000], Loss: 1.0176\n",
      "Iteration [503/1000], Loss: 1.0168\n",
      "Iteration [504/1000], Loss: 1.0064\n",
      "Iteration [505/1000], Loss: 1.0194\n",
      "Iteration [506/1000], Loss: 1.0056\n",
      "Iteration [507/1000], Loss: 1.0469\n",
      "Iteration [508/1000], Loss: 1.0220\n",
      "Iteration [509/1000], Loss: 1.0034\n",
      "Iteration [510/1000], Loss: 1.0169\n",
      "Iteration [511/1000], Loss: 1.0072\n",
      "Iteration [512/1000], Loss: 1.0042\n",
      "Iteration [513/1000], Loss: 1.0107\n",
      "Iteration [514/1000], Loss: 1.0022\n",
      "Iteration [515/1000], Loss: 1.0060\n",
      "Iteration [516/1000], Loss: 1.0008\n",
      "Iteration [517/1000], Loss: 1.0084\n",
      "Iteration [518/1000], Loss: 1.0044\n",
      "Iteration [519/1000], Loss: 1.0021\n",
      "Iteration [520/1000], Loss: 1.0024\n",
      "Iteration [521/1000], Loss: 1.0037\n",
      "Iteration [522/1000], Loss: 1.0033\n",
      "Iteration [523/1000], Loss: 1.0017\n",
      "Iteration [524/1000], Loss: 1.0041\n",
      "Iteration [525/1000], Loss: 1.0039\n",
      "Iteration [526/1000], Loss: 1.0025\n",
      "Iteration [527/1000], Loss: 1.0035\n",
      "Iteration [528/1000], Loss: 1.0058\n",
      "Iteration [529/1000], Loss: 1.0036\n",
      "Iteration [530/1000], Loss: 1.0012\n",
      "Iteration [531/1000], Loss: 1.0084\n",
      "Iteration [532/1000], Loss: 1.0082\n",
      "Iteration [533/1000], Loss: 1.0018\n",
      "Iteration [534/1000], Loss: 1.0036\n",
      "Iteration [535/1000], Loss: 1.0055\n",
      "Iteration [536/1000], Loss: 1.0041\n",
      "Iteration [537/1000], Loss: 1.0065\n",
      "Iteration [538/1000], Loss: 1.0029\n",
      "Iteration [539/1000], Loss: 1.0159\n",
      "Iteration [540/1000], Loss: 1.0014\n",
      "Iteration [541/1000], Loss: 1.0083\n",
      "Iteration [542/1000], Loss: 1.0060\n",
      "Iteration [543/1000], Loss: 1.0085\n",
      "Iteration [544/1000], Loss: 1.0041\n",
      "Iteration [545/1000], Loss: 1.0012\n",
      "Iteration [546/1000], Loss: 1.0056\n",
      "Iteration [547/1000], Loss: 1.0032\n",
      "Iteration [548/1000], Loss: 1.0025\n",
      "Iteration [549/1000], Loss: 1.0039\n",
      "Iteration [550/1000], Loss: 1.0079\n",
      "Iteration [551/1000], Loss: 1.0023\n",
      "Iteration [552/1000], Loss: 1.0025\n",
      "Iteration [553/1000], Loss: 1.0063\n",
      "Iteration [554/1000], Loss: 1.0139\n",
      "Iteration [555/1000], Loss: 1.0186\n",
      "Iteration [556/1000], Loss: 1.0127\n",
      "Iteration [557/1000], Loss: 1.0037\n",
      "Iteration [558/1000], Loss: 1.0173\n",
      "Iteration [559/1000], Loss: 1.0187\n",
      "Iteration [560/1000], Loss: 1.0015\n",
      "Iteration [561/1000], Loss: 1.0141\n",
      "Iteration [562/1000], Loss: 1.0029\n",
      "Iteration [563/1000], Loss: 1.0120\n",
      "Iteration [564/1000], Loss: 1.0283\n",
      "Iteration [565/1000], Loss: 1.0039\n",
      "Iteration [566/1000], Loss: 1.0133\n",
      "Iteration [567/1000], Loss: 1.0216\n",
      "Iteration [568/1000], Loss: 1.0021\n",
      "Iteration [569/1000], Loss: 1.0283\n",
      "Iteration [570/1000], Loss: 1.0452\n",
      "Iteration [571/1000], Loss: 1.0028\n",
      "Iteration [572/1000], Loss: 1.0433\n",
      "Iteration [573/1000], Loss: 1.0787\n",
      "Iteration [574/1000], Loss: 1.0269\n",
      "Iteration [575/1000], Loss: 1.0025\n",
      "Iteration [576/1000], Loss: 1.0258\n",
      "Iteration [577/1000], Loss: 1.0098\n",
      "Iteration [578/1000], Loss: 1.0193\n",
      "Iteration [579/1000], Loss: 1.0050\n",
      "Iteration [580/1000], Loss: 1.0144\n",
      "Iteration [581/1000], Loss: 1.0115\n",
      "Iteration [582/1000], Loss: 1.0015\n",
      "Iteration [583/1000], Loss: 1.0179\n",
      "Iteration [584/1000], Loss: 1.0423\n",
      "Iteration [585/1000], Loss: 1.0137\n",
      "Iteration [586/1000], Loss: 1.0082\n",
      "Iteration [587/1000], Loss: 1.0321\n",
      "Iteration [588/1000], Loss: 1.0155\n",
      "Iteration [589/1000], Loss: 1.0059\n",
      "Iteration [590/1000], Loss: 1.0142\n",
      "Iteration [591/1000], Loss: 1.0046\n",
      "Iteration [592/1000], Loss: 1.0103\n",
      "Iteration [593/1000], Loss: 1.0091\n",
      "Iteration [594/1000], Loss: 1.0052\n",
      "Iteration [595/1000], Loss: 1.0072\n",
      "Iteration [596/1000], Loss: 1.0311\n",
      "Iteration [597/1000], Loss: 1.0270\n",
      "Iteration [598/1000], Loss: 1.0042\n",
      "Iteration [599/1000], Loss: 1.0317\n",
      "Iteration [600/1000], Loss: 1.0298\n",
      "Iteration [601/1000], Loss: 1.0032\n",
      "Iteration [602/1000], Loss: 1.0409\n",
      "Iteration [603/1000], Loss: 1.0256\n",
      "Iteration [604/1000], Loss: 1.0017\n",
      "Iteration [605/1000], Loss: 1.0162\n",
      "Iteration [606/1000], Loss: 1.0150\n",
      "Iteration [607/1000], Loss: 1.0015\n",
      "Iteration [608/1000], Loss: 1.0094\n",
      "Iteration [609/1000], Loss: 1.0109\n",
      "Iteration [610/1000], Loss: 1.0006\n",
      "Iteration [611/1000], Loss: 1.0063\n",
      "Iteration [612/1000], Loss: 1.0050\n",
      "Iteration [613/1000], Loss: 1.0019\n",
      "Iteration [614/1000], Loss: 1.0147\n",
      "Iteration [615/1000], Loss: 1.0298\n",
      "Iteration [616/1000], Loss: 1.0108\n",
      "Iteration [617/1000], Loss: 1.0102\n",
      "Iteration [618/1000], Loss: 1.0426\n",
      "Iteration [619/1000], Loss: 1.0503\n",
      "Iteration [620/1000], Loss: 1.0070\n",
      "Iteration [621/1000], Loss: 1.0358\n",
      "Iteration [622/1000], Loss: 1.0006\n",
      "Iteration [623/1000], Loss: 1.0260\n",
      "Iteration [624/1000], Loss: 1.0170\n",
      "Iteration [625/1000], Loss: 1.0110\n",
      "Iteration [626/1000], Loss: 1.0395\n",
      "Iteration [627/1000], Loss: 1.0133\n",
      "Iteration [628/1000], Loss: 1.0040\n",
      "Iteration [629/1000], Loss: 1.0015\n",
      "Iteration [630/1000], Loss: 1.0033\n",
      "Iteration [631/1000], Loss: 1.0048\n",
      "Iteration [632/1000], Loss: 1.0107\n",
      "Iteration [633/1000], Loss: 1.0134\n",
      "Iteration [634/1000], Loss: 1.0055\n",
      "Iteration [635/1000], Loss: 1.0009\n",
      "Iteration [636/1000], Loss: 1.0036\n",
      "Iteration [637/1000], Loss: 1.0060\n",
      "Iteration [638/1000], Loss: 1.0134\n",
      "Iteration [639/1000], Loss: 1.0192\n",
      "Iteration [640/1000], Loss: 1.0313\n",
      "Iteration [641/1000], Loss: 1.0195\n",
      "Iteration [642/1000], Loss: 1.0148\n",
      "Iteration [643/1000], Loss: 1.0204\n",
      "Iteration [644/1000], Loss: 1.0085\n",
      "Iteration [645/1000], Loss: 1.0110\n",
      "Iteration [646/1000], Loss: 1.0158\n",
      "Iteration [647/1000], Loss: 1.0038\n",
      "Iteration [648/1000], Loss: 1.0055\n",
      "Iteration [649/1000], Loss: 1.0102\n",
      "Iteration [650/1000], Loss: 1.0122\n",
      "Iteration [651/1000], Loss: 1.0147\n",
      "Iteration [652/1000], Loss: 1.0128\n",
      "Iteration [653/1000], Loss: 1.0112\n",
      "Iteration [654/1000], Loss: 1.0786\n",
      "Iteration [655/1000], Loss: 1.0918\n",
      "Iteration [656/1000], Loss: 1.0279\n",
      "Iteration [657/1000], Loss: 1.0185\n",
      "Iteration [658/1000], Loss: 1.0185\n",
      "Iteration [659/1000], Loss: 1.0165\n",
      "Iteration [660/1000], Loss: 1.0250\n",
      "Iteration [661/1000], Loss: 1.0053\n",
      "Iteration [662/1000], Loss: 1.0053\n",
      "Iteration [663/1000], Loss: 1.0049\n",
      "Iteration [664/1000], Loss: 1.0026\n",
      "Iteration [665/1000], Loss: 1.0041\n",
      "Iteration [666/1000], Loss: 1.0077\n",
      "Iteration [667/1000], Loss: 1.0079\n",
      "Iteration [668/1000], Loss: 1.0063\n",
      "Iteration [669/1000], Loss: 1.0082\n",
      "Iteration [670/1000], Loss: 1.0044\n",
      "Iteration [671/1000], Loss: 1.0022\n",
      "Iteration [672/1000], Loss: 1.0042\n",
      "Iteration [673/1000], Loss: 1.0075\n",
      "Iteration [674/1000], Loss: 1.0045\n",
      "Iteration [675/1000], Loss: 1.0031\n",
      "Iteration [676/1000], Loss: 1.0031\n",
      "Iteration [677/1000], Loss: 1.0024\n",
      "Iteration [678/1000], Loss: 1.0006\n",
      "Iteration [679/1000], Loss: 1.0014\n",
      "Iteration [680/1000], Loss: 1.0010\n",
      "Iteration [681/1000], Loss: 1.0025\n",
      "Iteration [682/1000], Loss: 1.0012\n",
      "Iteration [683/1000], Loss: 1.0004\n",
      "Iteration [684/1000], Loss: 1.0020\n",
      "Iteration [685/1000], Loss: 1.0032\n",
      "Iteration [686/1000], Loss: 1.0006\n",
      "Iteration [687/1000], Loss: 1.0005\n",
      "Iteration [688/1000], Loss: 1.0041\n",
      "Iteration [689/1000], Loss: 1.0120\n",
      "Iteration [690/1000], Loss: 1.0054\n",
      "Iteration [691/1000], Loss: 1.0066\n",
      "Iteration [692/1000], Loss: 1.0068\n",
      "Iteration [693/1000], Loss: 1.0008\n",
      "Iteration [694/1000], Loss: 1.0083\n",
      "Iteration [695/1000], Loss: 1.0114\n",
      "Iteration [696/1000], Loss: 1.0021\n",
      "Iteration [697/1000], Loss: 1.0062\n",
      "Iteration [698/1000], Loss: 1.0062\n",
      "Iteration [699/1000], Loss: 1.0026\n",
      "Iteration [700/1000], Loss: 1.0197\n",
      "Iteration [701/1000], Loss: 1.0093\n",
      "Iteration [702/1000], Loss: 1.0203\n",
      "Iteration [703/1000], Loss: 1.0775\n",
      "Iteration [704/1000], Loss: 1.0817\n",
      "Iteration [705/1000], Loss: 1.0182\n",
      "Iteration [706/1000], Loss: 1.0215\n",
      "Iteration [707/1000], Loss: 1.0783\n",
      "Iteration [708/1000], Loss: 1.0186\n",
      "Iteration [709/1000], Loss: 1.0566\n",
      "Iteration [710/1000], Loss: 1.2432\n",
      "Iteration [711/1000], Loss: 1.0788\n",
      "Iteration [712/1000], Loss: 1.0814\n",
      "Iteration [713/1000], Loss: 1.2098\n",
      "Iteration [714/1000], Loss: 1.0112\n",
      "Iteration [715/1000], Loss: 1.1735\n",
      "Iteration [716/1000], Loss: 1.3567\n",
      "Iteration [717/1000], Loss: 1.1301\n",
      "Iteration [718/1000], Loss: 1.1501\n",
      "Iteration [719/1000], Loss: 1.3995\n",
      "Iteration [720/1000], Loss: 1.0426\n",
      "Iteration [721/1000], Loss: 1.4959\n",
      "Iteration [722/1000], Loss: 1.7321\n",
      "Iteration [723/1000], Loss: 1.3676\n",
      "Iteration [724/1000], Loss: 1.6767\n",
      "Iteration [725/1000], Loss: 1.6981\n",
      "Iteration [726/1000], Loss: 1.5285\n",
      "Iteration [727/1000], Loss: 1.5182\n",
      "Iteration [728/1000], Loss: 1.5616\n",
      "Iteration [729/1000], Loss: 1.2510\n",
      "Iteration [730/1000], Loss: 1.4222\n",
      "Iteration [731/1000], Loss: 1.1045\n",
      "Iteration [732/1000], Loss: 1.6478\n",
      "Iteration [733/1000], Loss: 1.4043\n",
      "Iteration [734/1000], Loss: 1.2276\n",
      "Iteration [735/1000], Loss: 1.7676\n",
      "Iteration [736/1000], Loss: 1.6043\n",
      "Iteration [737/1000], Loss: 1.1342\n",
      "Iteration [738/1000], Loss: 1.4625\n",
      "Iteration [739/1000], Loss: 1.3324\n",
      "Iteration [740/1000], Loss: 1.0901\n",
      "Iteration [741/1000], Loss: 1.1946\n",
      "Iteration [742/1000], Loss: 1.2992\n",
      "Iteration [743/1000], Loss: 1.1853\n",
      "Iteration [744/1000], Loss: 1.1416\n",
      "Iteration [745/1000], Loss: 1.1780\n",
      "Iteration [746/1000], Loss: 1.2004\n",
      "Iteration [747/1000], Loss: 1.4282\n",
      "Iteration [748/1000], Loss: 1.2342\n",
      "Iteration [749/1000], Loss: 1.0338\n",
      "Iteration [750/1000], Loss: 1.0347\n",
      "Iteration [751/1000], Loss: 1.1874\n",
      "Iteration [752/1000], Loss: 1.1128\n",
      "Iteration [753/1000], Loss: 1.1335\n",
      "Iteration [754/1000], Loss: 1.1674\n",
      "Iteration [755/1000], Loss: 1.1993\n",
      "Iteration [756/1000], Loss: 1.1601\n",
      "Iteration [757/1000], Loss: 1.0437\n",
      "Iteration [758/1000], Loss: 1.2111\n",
      "Iteration [759/1000], Loss: 1.1577\n",
      "Iteration [760/1000], Loss: 1.0098\n",
      "Iteration [761/1000], Loss: 1.0516\n",
      "Iteration [762/1000], Loss: 1.1727\n",
      "Iteration [763/1000], Loss: 1.0110\n",
      "Iteration [764/1000], Loss: 1.1251\n",
      "Iteration [765/1000], Loss: 1.0071\n",
      "Iteration [766/1000], Loss: 1.1227\n",
      "Iteration [767/1000], Loss: 1.0562\n",
      "Iteration [768/1000], Loss: 1.1077\n",
      "Iteration [769/1000], Loss: 1.0688\n",
      "Iteration [770/1000], Loss: 1.0862\n",
      "Iteration [771/1000], Loss: 1.0710\n",
      "Iteration [772/1000], Loss: 1.0295\n",
      "Iteration [773/1000], Loss: 1.0390\n",
      "Iteration [774/1000], Loss: 1.0220\n",
      "Iteration [775/1000], Loss: 1.0519\n",
      "Iteration [776/1000], Loss: 1.0052\n",
      "Iteration [777/1000], Loss: 1.0383\n",
      "Iteration [778/1000], Loss: 1.0080\n",
      "Iteration [779/1000], Loss: 1.0280\n",
      "Iteration [780/1000], Loss: 1.0041\n",
      "Iteration [781/1000], Loss: 1.0354\n",
      "Iteration [782/1000], Loss: 1.0049\n",
      "Iteration [783/1000], Loss: 1.0219\n",
      "Iteration [784/1000], Loss: 1.0107\n",
      "Iteration [785/1000], Loss: 1.0093\n",
      "Iteration [786/1000], Loss: 1.0089\n",
      "Iteration [787/1000], Loss: 1.0021\n",
      "Iteration [788/1000], Loss: 1.0042\n",
      "Iteration [789/1000], Loss: 1.0016\n",
      "Iteration [790/1000], Loss: 1.0037\n",
      "Iteration [791/1000], Loss: 1.0005\n",
      "Iteration [792/1000], Loss: 1.0014\n",
      "Iteration [793/1000], Loss: 1.0019\n",
      "Iteration [794/1000], Loss: 1.0077\n",
      "Iteration [795/1000], Loss: 1.0004\n",
      "Iteration [796/1000], Loss: 1.0053\n",
      "Iteration [797/1000], Loss: 1.0009\n",
      "Iteration [798/1000], Loss: 1.0063\n",
      "Iteration [799/1000], Loss: 1.0003\n",
      "Iteration [800/1000], Loss: 1.0026\n",
      "Iteration [801/1000], Loss: 1.0018\n",
      "Iteration [802/1000], Loss: 1.0017\n",
      "Iteration [803/1000], Loss: 1.0014\n",
      "Iteration [804/1000], Loss: 1.0019\n",
      "Iteration [805/1000], Loss: 1.0008\n",
      "Iteration [806/1000], Loss: 1.0019\n",
      "Iteration [807/1000], Loss: 1.0003\n",
      "Iteration [808/1000], Loss: 1.0028\n",
      "Iteration [809/1000], Loss: 1.0031\n",
      "Iteration [810/1000], Loss: 1.0005\n",
      "Iteration [811/1000], Loss: 1.0014\n",
      "Iteration [812/1000], Loss: 1.0018\n",
      "Iteration [813/1000], Loss: 1.0040\n",
      "Iteration [814/1000], Loss: 1.0004\n",
      "Iteration [815/1000], Loss: 1.0024\n",
      "Iteration [816/1000], Loss: 1.0002\n",
      "Iteration [817/1000], Loss: 1.0034\n",
      "Iteration [818/1000], Loss: 1.0001\n",
      "Iteration [819/1000], Loss: 1.0012\n",
      "Iteration [820/1000], Loss: 1.0001\n",
      "Iteration [821/1000], Loss: 1.0006\n",
      "Iteration [822/1000], Loss: 1.0007\n",
      "Iteration [823/1000], Loss: 1.0017\n",
      "Iteration [824/1000], Loss: 1.0006\n",
      "Iteration [825/1000], Loss: 1.0019\n",
      "Iteration [826/1000], Loss: 1.0003\n",
      "Iteration [827/1000], Loss: 1.0011\n",
      "Iteration [828/1000], Loss: 1.0011\n",
      "Iteration [829/1000], Loss: 1.0004\n",
      "Iteration [830/1000], Loss: 1.0002\n",
      "Iteration [831/1000], Loss: 1.0010\n",
      "Iteration [832/1000], Loss: 1.0012\n",
      "Iteration [833/1000], Loss: 1.0000\n",
      "Iteration [834/1000], Loss: 1.0010\n",
      "Iteration [835/1000], Loss: 1.0012\n",
      "Iteration [836/1000], Loss: 1.0017\n",
      "Iteration [837/1000], Loss: 1.0003\n",
      "Iteration [838/1000], Loss: 1.0006\n",
      "Iteration [839/1000], Loss: 1.0002\n",
      "Iteration [840/1000], Loss: 1.0007\n",
      "Iteration [841/1000], Loss: 1.0007\n",
      "Iteration [842/1000], Loss: 1.0001\n",
      "Iteration [843/1000], Loss: 1.0012\n",
      "Iteration [844/1000], Loss: 1.0006\n",
      "Iteration [845/1000], Loss: 1.0002\n",
      "Iteration [846/1000], Loss: 1.0022\n",
      "Iteration [847/1000], Loss: 1.0042\n",
      "Iteration [848/1000], Loss: 1.0003\n",
      "Iteration [849/1000], Loss: 1.0027\n",
      "Iteration [850/1000], Loss: 1.0004\n",
      "Iteration [851/1000], Loss: 1.0029\n",
      "Iteration [852/1000], Loss: 1.0017\n",
      "Iteration [853/1000], Loss: 1.0030\n",
      "Iteration [854/1000], Loss: 1.0084\n",
      "Iteration [855/1000], Loss: 1.0005\n",
      "Iteration [856/1000], Loss: 1.0042\n",
      "Iteration [857/1000], Loss: 1.0007\n",
      "Iteration [858/1000], Loss: 1.0036\n",
      "Iteration [859/1000], Loss: 1.0031\n",
      "Iteration [860/1000], Loss: 1.0006\n",
      "Iteration [861/1000], Loss: 1.0020\n",
      "Iteration [862/1000], Loss: 1.0004\n",
      "Iteration [863/1000], Loss: 1.0011\n",
      "Iteration [864/1000], Loss: 1.0017\n",
      "Iteration [865/1000], Loss: 1.0075\n",
      "Iteration [866/1000], Loss: 1.0003\n",
      "Iteration [867/1000], Loss: 1.0065\n",
      "Iteration [868/1000], Loss: 1.0011\n",
      "Iteration [869/1000], Loss: 1.0045\n",
      "Iteration [870/1000], Loss: 1.0033\n",
      "Iteration [871/1000], Loss: 1.0015\n",
      "Iteration [872/1000], Loss: 1.0022\n",
      "Iteration [873/1000], Loss: 1.0009\n",
      "Iteration [874/1000], Loss: 1.0009\n",
      "Iteration [875/1000], Loss: 1.0005\n",
      "Iteration [876/1000], Loss: 1.0020\n",
      "Iteration [877/1000], Loss: 1.0006\n",
      "Iteration [878/1000], Loss: 1.0013\n",
      "Iteration [879/1000], Loss: 1.0009\n",
      "Iteration [880/1000], Loss: 1.0012\n",
      "Iteration [881/1000], Loss: 1.0037\n",
      "Iteration [882/1000], Loss: 1.0003\n",
      "Iteration [883/1000], Loss: 1.0040\n",
      "Iteration [884/1000], Loss: 1.0008\n",
      "Iteration [885/1000], Loss: 1.0047\n",
      "Iteration [886/1000], Loss: 1.0023\n",
      "Iteration [887/1000], Loss: 1.0021\n",
      "Iteration [888/1000], Loss: 1.0032\n",
      "Iteration [889/1000], Loss: 1.0010\n",
      "Iteration [890/1000], Loss: 1.0033\n",
      "Iteration [891/1000], Loss: 1.0004\n",
      "Iteration [892/1000], Loss: 1.0041\n",
      "Iteration [893/1000], Loss: 1.0049\n",
      "Iteration [894/1000], Loss: 1.0004\n",
      "Iteration [895/1000], Loss: 1.0050\n",
      "Iteration [896/1000], Loss: 1.0003\n",
      "Iteration [897/1000], Loss: 1.0027\n",
      "Iteration [898/1000], Loss: 1.0004\n",
      "Iteration [899/1000], Loss: 1.0023\n",
      "Iteration [900/1000], Loss: 1.0010\n",
      "Iteration [901/1000], Loss: 1.0017\n",
      "Iteration [902/1000], Loss: 1.0033\n",
      "Iteration [903/1000], Loss: 1.0009\n",
      "Iteration [904/1000], Loss: 1.0010\n",
      "Iteration [905/1000], Loss: 1.0012\n",
      "Iteration [906/1000], Loss: 1.0004\n",
      "Iteration [907/1000], Loss: 1.0014\n",
      "Iteration [908/1000], Loss: 1.0005\n",
      "Iteration [909/1000], Loss: 1.0010\n",
      "Iteration [910/1000], Loss: 1.0006\n",
      "Iteration [911/1000], Loss: 1.0017\n",
      "Iteration [912/1000], Loss: 1.0006\n",
      "Iteration [913/1000], Loss: 1.0013\n",
      "Iteration [914/1000], Loss: 1.0006\n",
      "Iteration [915/1000], Loss: 1.0020\n",
      "Iteration [916/1000], Loss: 1.0006\n",
      "Iteration [917/1000], Loss: 1.0049\n",
      "Iteration [918/1000], Loss: 1.0054\n",
      "Iteration [919/1000], Loss: 1.0003\n",
      "Iteration [920/1000], Loss: 1.0025\n",
      "Iteration [921/1000], Loss: 1.0016\n",
      "Iteration [922/1000], Loss: 1.0011\n",
      "Iteration [923/1000], Loss: 1.0030\n",
      "Iteration [924/1000], Loss: 1.0005\n",
      "Iteration [925/1000], Loss: 1.0017\n",
      "Iteration [926/1000], Loss: 1.0004\n",
      "Iteration [927/1000], Loss: 1.0013\n",
      "Iteration [928/1000], Loss: 1.0029\n",
      "Iteration [929/1000], Loss: 1.0007\n",
      "Iteration [930/1000], Loss: 1.0044\n",
      "Iteration [931/1000], Loss: 1.0011\n",
      "Iteration [932/1000], Loss: 1.0003\n",
      "Iteration [933/1000], Loss: 1.0004\n",
      "Iteration [934/1000], Loss: 1.0018\n",
      "Iteration [935/1000], Loss: 1.0003\n",
      "Iteration [936/1000], Loss: 1.0037\n",
      "Iteration [937/1000], Loss: 1.0003\n",
      "Iteration [938/1000], Loss: 1.0051\n",
      "Iteration [939/1000], Loss: 1.0011\n",
      "Iteration [940/1000], Loss: 1.0092\n",
      "Iteration [941/1000], Loss: 1.0103\n",
      "Iteration [942/1000], Loss: 1.0014\n",
      "Iteration [943/1000], Loss: 1.0030\n",
      "Iteration [944/1000], Loss: 1.0024\n",
      "Iteration [945/1000], Loss: 1.0015\n",
      "Iteration [946/1000], Loss: 1.0041\n",
      "Iteration [947/1000], Loss: 1.0009\n",
      "Iteration [948/1000], Loss: 1.0077\n",
      "Iteration [949/1000], Loss: 1.0002\n",
      "Iteration [950/1000], Loss: 1.0089\n",
      "Iteration [951/1000], Loss: 1.0021\n",
      "Iteration [952/1000], Loss: 1.0076\n",
      "Iteration [953/1000], Loss: 1.0077\n",
      "Iteration [954/1000], Loss: 1.0016\n",
      "Iteration [955/1000], Loss: 1.0040\n",
      "Iteration [956/1000], Loss: 1.0013\n",
      "Iteration [957/1000], Loss: 1.0058\n",
      "Iteration [958/1000], Loss: 1.0007\n",
      "Iteration [959/1000], Loss: 1.0079\n",
      "Iteration [960/1000], Loss: 1.0046\n",
      "Iteration [961/1000], Loss: 1.0008\n",
      "Iteration [962/1000], Loss: 1.0046\n",
      "Iteration [963/1000], Loss: 1.0007\n",
      "Iteration [964/1000], Loss: 1.0038\n",
      "Iteration [965/1000], Loss: 1.0006\n",
      "Iteration [966/1000], Loss: 1.0022\n",
      "Iteration [967/1000], Loss: 1.0003\n",
      "Iteration [968/1000], Loss: 1.0021\n",
      "Iteration [969/1000], Loss: 1.0023\n",
      "Iteration [970/1000], Loss: 1.0012\n",
      "Iteration [971/1000], Loss: 1.0041\n",
      "Iteration [972/1000], Loss: 1.0009\n",
      "Iteration [973/1000], Loss: 1.0022\n",
      "Iteration [974/1000], Loss: 1.0036\n",
      "Iteration [975/1000], Loss: 1.0004\n",
      "Iteration [976/1000], Loss: 1.0035\n",
      "Iteration [977/1000], Loss: 1.0008\n",
      "Iteration [978/1000], Loss: 1.0010\n",
      "Iteration [979/1000], Loss: 1.0005\n",
      "Iteration [980/1000], Loss: 1.0014\n",
      "Iteration [981/1000], Loss: 1.0011\n",
      "Iteration [982/1000], Loss: 1.0004\n",
      "Iteration [983/1000], Loss: 1.0006\n",
      "Iteration [984/1000], Loss: 1.0001\n",
      "Iteration [985/1000], Loss: 1.0005\n",
      "Iteration [986/1000], Loss: 1.0004\n",
      "Iteration [987/1000], Loss: 1.0009\n",
      "Iteration [988/1000], Loss: 1.0012\n",
      "Iteration [989/1000], Loss: 1.0009\n",
      "Iteration [990/1000], Loss: 1.0034\n",
      "Iteration [991/1000], Loss: 1.0010\n",
      "Iteration [992/1000], Loss: 1.0012\n",
      "Iteration [993/1000], Loss: 1.0015\n",
      "Iteration [994/1000], Loss: 1.0006\n",
      "Iteration [995/1000], Loss: 1.0024\n",
      "Iteration [996/1000], Loss: 1.0001\n",
      "Iteration [997/1000], Loss: 1.0027\n",
      "Iteration [998/1000], Loss: 1.0004\n",
      "Iteration [999/1000], Loss: 1.0032\n",
      "Iteration [1000/1000], Loss: 1.0042\n"
     ]
    }
   ],
   "source": [
    "def DDM(mu, sequence_length, sigma=0.5, dt=1, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed) \n",
    "    num_trajectories = len(mu)\n",
    "    num_steps = int(sequence_length / dt)\n",
    "    x = np.zeros((num_trajectories, num_steps + 1))\n",
    "\n",
    "    for i in range(num_trajectories):\n",
    "        for t in range(num_steps):\n",
    "            x[i, t + 1] = x[i, t] + mu[i] * dt + sigma * np.sqrt(dt) * np.random.normal()\n",
    "    \n",
    "    p = np.sign(mu)\n",
    "    x = x[:, :, None]\n",
    "    return torch.tensor(x, dtype=torch.float32), torch.tensor(p, dtype=torch.long)\n",
    "\n",
    "def mse_loss(z, p):\n",
    "    return ((z - p)**2).mean()\n",
    "    \n",
    "class DriftDiffusionRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, input_size, output_size):\n",
    "        super(DriftDiffusionRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = torch.nn.RNNCell(input_size, hidden_size, nonlinearity='tanh')\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_i = torch.zeros(x.shape[0], self.hidden_size)\n",
    "        z = torch.zeros(x.shape[0], 1)\n",
    "        mask = torch.ones(x.shape[0], 1, dtype=torch.bool)  #array of True \n",
    "        ls_h_i = []\n",
    "        for i in range(x.shape[1]):\n",
    "            h_i = self.rnn(x[:, i], h_i)\n",
    "            output = self.fc(h_i)\n",
    "            z += output * mask \n",
    "\n",
    "            mask = torch.logical_and(mask, z.abs() < 1)    #False if threshold is reached\n",
    "\n",
    "            ls_h_i.append(h_i)\n",
    "            if mask.sum() == 0:\n",
    "                break\n",
    "\n",
    "        return z, ls_h_i\n",
    "\n",
    "def train_model(model, optimizer, mu, iterations=10, sequence_length=50, save_path = 'model.pth'):\n",
    "    model.train()\n",
    "    ls_loss = []\n",
    "    for iter in range(iterations):\n",
    "        x, p = DDM(mu, sequence_length)\n",
    "        optimizer.zero_grad()\n",
    "        z, ls_h_i = model(x)  \n",
    "        loss = mse_loss(z, p)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ls_loss.append(loss.item())\n",
    "        print(f'Iteration [{iter+1}/{iterations}], Loss: {loss.item():.4f}')\n",
    "    #torch.save(model.state_dict(), save_path)\n",
    "    return ls_loss\n",
    "\n",
    "mu = np.array([-0.64, -0.16, -0.04, 0.04, 0.16,0.64])  \n",
    "\n",
    "lr=1e-3\n",
    "model = DriftDiffusionRNN(hidden_size=100, input_size=1, output_size=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "sequence_length=50\n",
    "ls_loss = train_model(model, optimizer, mu,  iterations=1000,  sequence_length=50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291e009a0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ls_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, p = DDM(mu, sequence_length=50)\n",
    "z, ls_h_i = model(x)\n",
    "\n",
    "ls_X = [jnp.array(tensor.detach().numpy()) for tensor in ls_h_i]\n",
    "X = jnp.stack(ls_X, axis=1).swapaxes(1,2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sca_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
